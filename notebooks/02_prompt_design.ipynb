{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb039270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.preprocess import format_medical_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample\n",
    "sample = {\n",
    "    'question': 'What are the symptoms of type 2 diabetes?',\n",
    "    'answer': 'Common symptoms include increased thirst, frequent urination, increased hunger, fatigue, and blurred vision.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 1: Chat template\n",
    "prompt_v1 = format_medical_prompt(sample)\n",
    "print(\"=\" * 50)\n",
    "print(\"Prompt Version 1: Chat Template\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc959c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 2: Instruction-following\n",
    "def format_instruction_prompt(sample):\n",
    "    return f\"\"\"### Instruction:\n",
    "You are a medical AI assistant. Answer the following medical question accurately and concisely.\n",
    "\n",
    "### Question:\n",
    "{sample['question']}\n",
    "\n",
    "### Answer:\n",
    "{sample['answer']}\"\"\"\n",
    "\n",
    "prompt_v2 = format_instruction_prompt(sample)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Prompt Version 2: Instruction Format\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 3: Few-shot with context\n",
    "def format_fewshot_prompt(sample, context_examples=None):\n",
    "    prompt = \"Below are examples of medical question-answer pairs:\\n\\n\"\n",
    "    \n",
    "    if context_examples:\n",
    "        for i, ex in enumerate(context_examples, 1):\n",
    "            prompt += f\"Example {i}:\\nQ: {ex['question']}\\nA: {ex['answer']}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Now answer this question:\\nQ: {sample['question']}\\nA: {sample['answer']}\"\n",
    "    return prompt\n",
    "\n",
    "# Test with context\n",
    "context = [\n",
    "    {'question': 'What is hypertension?', 'answer': 'High blood pressure affecting blood vessels.'}\n",
    "]\n",
    "prompt_v3 = format_fewshot_prompt(sample, context)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Prompt Version 3: Few-Shot Format\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare token counts\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "\n",
    "prompts = [prompt_v1, prompt_v2, prompt_v3]\n",
    "names = [\"Chat\", \"Instruction\", \"Few-Shot\"]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Token Count Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, prompt in zip(names, prompts):\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    print(f\"{name}: {len(tokens)} tokens\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
